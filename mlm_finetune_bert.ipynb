{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset\nfrom datasets import load_dataset\nfrom transformers import BertTokenizer, BertForMaskedLM, DataCollatorForLanguageModeling, AutoTokenizer\nfrom tqdm.notebook import tqdm\nimport time\nimport numpy as np\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:10.161864Z","iopub.execute_input":"2024-07-18T12:37:10.162763Z","iopub.status.idle":"2024-07-18T12:37:27.766682Z","shell.execute_reply.started":"2024-07-18T12:37:10.162729Z","shell.execute_reply":"2024-07-18T12:37:27.765686Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-18 12:37:18.276733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-18 12:37:18.276834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-18 12:37:18.419535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrainset_range = list(range(18000, 28000))\nnum_epochs = 5\nbatch_size = 32\nlr = 2e-5","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:27.768590Z","iopub.execute_input":"2024-07-18T12:37:27.769910Z","iopub.status.idle":"2024-07-18T12:37:27.806120Z","shell.execute_reply.started":"2024-07-18T12:37:27.769873Z","shell.execute_reply":"2024-07-18T12:37:27.804994Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n# model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n\ntokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\nmodel = BertForMaskedLM.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:27.807536Z","iopub.execute_input":"2024-07-18T12:37:27.808001Z","iopub.status.idle":"2024-07-18T12:37:32.544107Z","shell.execute_reply.started":"2024-07-18T12:37:27.807969Z","shell.execute_reply":"2024-07-18T12:37:32.543284Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650b02443d3e4775b3f595f21c9875fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21bd8aea443e4bf3b9f639d2bf9a9617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c3d5dae1fe4792afbfd5d72a6ec67b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_none(example):\n    return example[\"exp\"] is not None\n\n\ndef mlm_map_function(rows):\n    # Tokenize the text with specified tokenizer parameters\n    input_info = tokenizer(\n        rows[\"exp\"],\n        max_length=128,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n    return {**input_info, \"labels\": input_info[\"input_ids\"]}\n\n\n# load MedMCQA\ndataset = load_dataset(\"openlifescienceai/medmcqa\")\n# mlm_dataset = Subset(dataset[\"train\"], trainset_range)\nmlm_dataset = dataset[\"train\"].select(trainset_range)\nmlm_dataset = mlm_dataset.filter(filter_none).select_columns([\"exp\"])\nmlm_dataset = mlm_dataset.map(\n    mlm_map_function,\n    batched=True,\n    num_proc=2,\n)\nprint(mlm_dataset)\n\ncollate_fn = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n# train_loader = DataLoader(\n#     mlm_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n# )","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:32.546404Z","iopub.execute_input":"2024-07-18T12:37:32.546703Z","iopub.status.idle":"2024-07-18T12:37:55.210699Z","shell.execute_reply.started":"2024-07-18T12:37:32.546678Z","shell.execute_reply":"2024-07-18T12:37:55.209566Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21583370d3f04543a40895c3fd783afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/85.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd7fe439fce4b078cb51aa0c6f12e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/936k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96bb9dfd27de4f7a87cb761aeec6f6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c45d40d53ec43e48d0973e9f8cab402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da9c46c5fbb4549ba941db05a6d885f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01228d668dc8406fa637ee1b47e3cdf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315fbe46ff904950b5b26e93f51887a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8267ee846bc64bf1bbb5c0a4a597841a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/8803 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7436f386fdc54be3b44d0e3d25e30c6c"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['exp', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 8803\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hugging Face Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    logging_steps=len(mlm_dataset) // batch_size,  # Log per epoch\n    report_to=[],  # Disable wandb logging\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=collate_fn,\n    train_dataset=mlm_dataset,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:55.212413Z","iopub.execute_input":"2024-07-18T12:37:55.213180Z","iopub.status.idle":"2024-07-18T12:49:05.256138Z","shell.execute_reply.started":"2024-07-18T12:37:55.213141Z","shell.execute_reply":"2024-07-18T12:49:05.255186Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1380' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1380/1380 11:06, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>275</td>\n      <td>2.117800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.872500</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>1.783200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.720300</td>\n    </tr>\n    <tr>\n      <td>1375</td>\n      <td>1.719400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1380, training_loss=1.8421367507050004, metrics={'train_runtime': 668.1489, 'train_samples_per_second': 65.876, 'train_steps_per_second': 2.065, 'total_flos': 2896188374676480.0, 'train_loss': 1.8421367507050004, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint_file = \"BioClinicalBert-MLM-Finetuned.pth\"\ntorch.save(\n    {\n        \"model_state_dict\": model.state_dict(),\n    },\n    checkpoint_file,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:58:16.949970Z","iopub.execute_input":"2024-07-18T12:58:16.950902Z","iopub.status.idle":"2024-07-18T12:58:17.513072Z","shell.execute_reply.started":"2024-07-18T12:58:16.950862Z","shell.execute_reply":"2024-07-18T12:58:17.511979Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\n# generate a token from Profile > Setting > Access Tokens with write access\napi = HfApi(\n    token=\"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\",\n)\napi.upload_file(\n    path_or_fileobj=\"./BioClinicalBert-MLM-Finetuned.pth\",\n    path_in_repo=\"BioClinicalBert-MLM-Finetuned.pth\",\n    repo_id=\"alibababeig/nlp-hw4-dataset\",\n    repo_type=\"model\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:01:30.161324Z","iopub.execute_input":"2024-07-18T13:01:30.161783Z","iopub.status.idle":"2024-07-18T13:01:44.681266Z","shell.execute_reply.started":"2024-07-18T13:01:30.161744Z","shell.execute_reply":"2024-07-18T13:01:44.680317Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"BioClinicalBert-MLM-Fintuned.pth:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57149a824a6b4c1f86bb934acb4a84d6"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/alibababeig/nlp-hw4-dataset/commit/d206173d9eabdd95c4c608069896e48e596a0ba4', commit_message='Upload BioClinicalBert-MLM-Fintuned.pth with huggingface_hub', commit_description='', oid='d206173d9eabdd95c4c608069896e48e596a0ba4', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"# # works for both train and test\n# def run_epoch(\n#     model,\n#     optimizer,\n#     data_loader,\n#     criterion,\n#     device,\n#     results,\n#     score_funcs=None,\n#     prefix=\"\",\n#     desc=None,\n# ):\n#     running_loss = []\n#     y_true = []\n#     y_pred = []\n#     start = time.time()\n#     for inputs, labels in tqdm(data_loader, desc=desc, leave=False):\n        \n#         inputs = inputs.to(device)\n#         labels = labels.to(device)\n\n#         y_hat = model(inputs)\n#         loss = criterion(y_hat, labels)\n\n#         if model.training:\n#             loss.backward()\n#             optimizer.step()\n#             optimizer.zero_grad()\n\n#         # Store metrics\n#         running_loss.append(loss.item())\n#         if score_funcs is None:\n#             score_funcs = {}\n#         if len(score_funcs) > 0 and isinstance(labels, torch.Tensor):\n#             # moving labels & predictions back to CPU for computing / storing predictions\n#             labels = labels.detach().cpu().numpy()\n#             y_hat = y_hat.detach().cpu().numpy()\n#             # add to predictions so far\n#             y_true.extend(labels.tolist())\n#             y_pred.extend(y_hat.tolist())\n\n#     end = time.time()\n\n#     y_pred = np.asarray(y_pred)\n#     if (\n#         len(y_pred.shape) == 2 and y_pred.shape[1] > 1\n#     ):  # We have a classification problem, convert to labels\n#         y_pred = np.argmax(y_pred, axis=1)\n#     # Else, we assume we are working on a regression problem\n\n#     results[prefix + \" loss\"].append(np.mean(running_loss))\n#     for name, score_func in score_funcs.items():\n#         try:\n#             results[prefix + \" \" + name].append(score_func(y_true, y_pred))\n#         except:\n#             results[prefix + \" \" + name].append(float(\"NaN\"))\n#     return end - start\n\n\n# def train_model(\n#     model,\n#     criterion,\n#     train_loader,\n#     val_loader=None,\n#     test_loader=None,\n#     score_funcs=None,\n#     epochs=50,\n#     device=\"cpu\",\n#     checkpoint_file=None,\n#     lr_scheduler=None,\n#     optimizer=None,\n#     disable_tqdm=False,\n#     log_items=(),\n# ):\n#     to_track = [\"epoch\", \"total time\", \"train loss\"]\n#     if val_loader is not None:\n#         to_track.append(\"val loss\")\n#     if test_loader is not None:\n#         to_track.append(\"test loss\")\n#     if score_funcs is not None:\n#         for eval_score in score_funcs:\n#             to_track.append(\"train \" + eval_score)\n#             if val_loader is not None:\n#                 to_track.append(\"val \" + eval_score)\n#             if test_loader is not None:\n#                 to_track.append(\"test \" + eval_score)\n\n#     # Initialization\n#     total_train_time = 0\n#     results = {}\n#     for item in to_track:\n#         results[item] = []\n\n#     if optimizer == None:\n#         optimizer = torch.optim.AdamW(model.parameters())\n\n#     model.to(device)\n#     pbar = tqdm(range(epochs), desc=\"Epoch\", disable=disable_tqdm)\n#     for epoch in pbar:\n#         model = model.train()\n\n#         total_train_time += run_epoch(\n#             model=model,\n#             optimizer=optimizer,\n#             data_loader=train_loader,\n#             criterion=criterion,\n#             device=device,\n#             results=results,\n#             score_funcs=score_funcs,\n#             prefix=\"train\",\n#             desc=\"Training\",\n#         )\n\n#         results[\"epoch\"].append(epoch)\n#         results[\"total time\"].append(total_train_time)\n\n#         # Predict the validation set\n#         if val_loader is not None:\n#             model = model.eval()\n#             with torch.no_grad():\n#                 run_epoch(\n#                     model=model,\n#                     optimizer=optimizer,\n#                     data_loader=val_loader,\n#                     criterion=criterion,\n#                     device=device,\n#                     results=results,\n#                     score_funcs=score_funcs,\n#                     prefix=\"val\",\n#                     desc=\"Validating\",\n#                 )\n\n#         if lr_scheduler is not None:\n#             if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n#                 lr_scheduler.step(results[\"val loss\"][-1])\n#             else:\n#                 lr_scheduler.step()\n\n#         # Predict the validation set\n#         if test_loader is not None:\n#             model = model.eval()\n#             with torch.no_grad():\n#                 run_epoch(\n#                     model=model,\n#                     optimizer=optimizer,\n#                     data_loader=test_loader,\n#                     criterion=criterion,\n#                     device=device,\n#                     results=results,\n#                     score_funcs=score_funcs,\n#                     prefix=\"test\",\n#                     desc=\"Testing\",\n#                 )\n\n#         log_postfix = {}\n#         log_str = f\"Epoch [{epoch+1}]: \"\n#         for log_item in log_items:\n#             log_postfix[log_item] = results[log_item][-1]\n#             log_str += f\"{log_item}: {results[log_item][-1]:.4f}, \"\n\n#         pbar.set_postfix(log_postfix)\n#         print(log_str)\n\n#     if checkpoint_file is not None:\n#         torch.save(\n#             {\n#                 \"epoch\": epoch,\n#                 \"model_state_dict\": model.state_dict(),\n#                 \"optimizer_state_dict\": optimizer.state_dict(),\n#                 \"results\": results,\n#             },\n#             checkpoint_file,\n#         )\n\n#     return results","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:05.257597Z","iopub.execute_input":"2024-07-18T12:49:05.257912Z","iopub.status.idle":"2024-07-18T12:49:05.268887Z","shell.execute_reply.started":"2024-07-18T12:49:05.257884Z","shell.execute_reply":"2024-07-18T12:49:05.268065Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n# score_funcs = {\"acc\": accuracy_score}\n# checkpoint_file = \"model_checkpoint.pth\"\n\n# results = train_model(\n#     model=model,\n#     criterion=criterion,\n#     train_loader=train_loader,\n#     val_loader=None,\n#     test_loader=None,\n#     optimizer=optimizer,\n#     lr_scheduler=scheduler,\n#     score_funcs=score_funcs,\n#     epochs=num_epochs,\n#     device=device,\n#     checkpoint_file=checkpoint_file,\n#     disable_tqdm=False,\n#     log_items=(\"train loss\", \"val loss\", \"train acc\", \"val acc\"),\n# )","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:05.269976Z","iopub.execute_input":"2024-07-18T12:49:05.270251Z","iopub.status.idle":"2024-07-18T12:49:05.285045Z","shell.execute_reply.started":"2024-07-18T12:49:05.270220Z","shell.execute_reply":"2024-07-18T12:49:05.284064Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # Define training loop with progress bar\n# optimizer =   # Adjust learning rate as needed\n# num_epochs = 3  # Adjust number of epochs for training\n\n# for epoch in tqdm(range(num_epochs)):\n#     model.train()\n#     losses = []\n\n#     for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n#         optimizer.zero_grad()\n#         outputs = model(**batch)  # Unpack batch data using the model\n#         loss = outputs.loss\n#         loss.backward()\n#         optimizer.step()\n#         losses.append(loss.item())\n\n#     avg_loss = sum(losses) / len(losses)\n#     print(f\"Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n\n# # Save the fine-tuned model (optional)\n# model.save_pretrained(\"fine-tuned_bert_model\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:05.286103Z","iopub.execute_input":"2024-07-18T12:49:05.286448Z","iopub.status.idle":"2024-07-18T12:49:05.298364Z","shell.execute_reply.started":"2024-07-18T12:49:05.286425Z","shell.execute_reply":"2024-07-18T12:49:05.297564Z"},"trusted":true},"execution_count":8,"outputs":[]}]}